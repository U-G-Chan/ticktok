<template>
    <div 
        class="camera-screen" 
        :class="effectBinding"
    >
        <video ref="videoEl" class="video" autoplay playsinline v-if="!noCamera"></video>
        <div v-if="noCamera" class="no-camera-message">
            <div class="message-content">
                <div class="message-icon">ğŸ“·</div>
                <div class="message-text">æœªæ£€æµ‹åˆ°æ‘„åƒå¤´</div>
                <div class="message-subtext">è¯·ä½¿ç”¨å…¶ä»–æ–¹å¼ä¸Šä¼ ç…§ç‰‡</div>
            </div>
        </div>
    </div>
</template>

<script lang="ts">
import { defineComponent, ref, onMounted, onUnmounted, computed } from 'vue'
import { CameraDirection } from '@/utils/web-capacitor-adapter'
import { 
    CaptureEffectType, 
    createEffectClassBinding,
    getEffectDuration
} from './captureEffects'

export default defineComponent({
    name: 'CameraScreen',
    emits: ['image-confirmed'],
    setup(_, { emit }) {
        const videoEl = ref<HTMLVideoElement | null>(null)
        let mediaStream: MediaStream | null = null
        const captureEffectActive = ref<boolean>(false)
        const noCamera = ref<boolean>(false)
        
        // å½“å‰ä½¿ç”¨çš„æ‹ç…§æ•ˆæœç±»å‹
        const captureEffectType = ref<CaptureEffectType>('pulse')

        // è®¡ç®—å½“å‰æ•ˆæœçš„ç±»ç»‘å®š
        const effectBinding = computed(() => 
            createEffectClassBinding(captureEffectType.value, captureEffectActive.value)
        )

        const initializeCamera = async (direction: string = CameraDirection.Rear) => {
            try {
                // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒgetUserMedia
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    console.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´åŠŸèƒ½')
                    noCamera.value = true
                    return
                }

                // åœæ­¢ä¹‹å‰çš„æµ
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop())
                }

                // è¯·æ±‚æ‘„åƒå¤´æƒé™
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: direction === CameraDirection.Front ? 'user' : 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                })

                // è®¾ç½®è§†é¢‘æº
                if (videoEl.value) {
                    videoEl.value.srcObject = mediaStream
                }

                // é‡ç½®æ•è·çŠ¶æ€
                noCamera.value = false
            } catch (error) {
                console.error('æ— æ³•è®¿é—®æ‘„åƒå¤´:', error)
                noCamera.value = true
            }
        }

        const switchCamera = (direction: string) => {
            initializeCamera(direction)
        }

        const toggleFlash = async (enabled: boolean) => {
            if (!mediaStream || noCamera.value) return

            try {
                const track = mediaStream.getVideoTracks()[0]
                if (track) {
                    const capabilities = track.getCapabilities()
                    // æ£€æŸ¥æ˜¯å¦æ”¯æŒé—ªå…‰ç¯
                    if ('torch' in capabilities) {
                        await track.applyConstraints({
                            advanced: [{ torch: enabled } as any]
                        })
                    } else {
                        console.warn('å½“å‰è®¾å¤‡ä¸æ”¯æŒé—ªå…‰ç¯æ§åˆ¶')
                    }
                }
            } catch (error) {
                console.error('æ§åˆ¶é—ªå…‰ç¯å¤±è´¥:', error)
            }
        }
        
        // è®¾ç½®æ‹ç…§æ•ˆæœç±»å‹
        const setCaptureEffectType = (type: CaptureEffectType) => {
            captureEffectType.value = type
            // console.log(`å·²åˆ‡æ¢åˆ°${type}æ‹ç…§æ•ˆæœ`)
        }

        // æ’­æ”¾æ‹ç…§æ•ˆæœ
        const playCaptureEffect = () => {
            captureEffectActive.value = true
            
            // è·å–å½“å‰æ•ˆæœçš„æŒç»­æ—¶é—´
            const duration = getEffectDuration(captureEffectType.value)
            
            setTimeout(() => {
                captureEffectActive.value = false
            }, duration)
        }

        const captureImage = async (): Promise<string | null> => {
            if (noCamera.value) {
                // æ²¡æœ‰æ‘„åƒå¤´æ—¶ï¼Œæ‰“å¼€æ–‡ä»¶é€‰æ‹©å™¨
                return new Promise((resolve, reject) => {
                    const input = document.createElement('input')
                    input.type = 'file'
                    input.accept = 'image/*'
                    
                    input.onchange = (e: Event) => {
                        const target = e.target as HTMLInputElement
                        if (target.files && target.files[0]) {
                            const file = target.files[0]
                            const reader = new FileReader()
                            reader.onload = () => {
                                const imageUrl = reader.result as string
                                // æ’­æ”¾æ‹ç…§æ•ˆæœ
                                playCaptureEffect()
                                // ç›´æ¥ç¡®è®¤å›¾ç‰‡ï¼Œæ— éœ€æ˜¾ç¤ºé¢„è§ˆ
                                emit('image-confirmed', imageUrl)
                                resolve(imageUrl)
                            }
                            reader.onerror = reject
                            reader.readAsDataURL(file)
                        } else {
                            reject(new Error('æœªé€‰æ‹©å›¾ç‰‡'))
                        }
                    }
                    
                    input.click()
                })
            }
            
            if (!videoEl.value || !mediaStream) return null

            try {
                // åˆ›å»ºcanvaså…ƒç´ 
                const canvas = document.createElement('canvas')
                canvas.width = videoEl.value.videoWidth
                canvas.height = videoEl.value.videoHeight
                const ctx = canvas.getContext('2d')
                if (ctx) {
                    ctx.drawImage(videoEl.value, 0, 0)
                    // è½¬æ¢ä¸ºå›¾ç‰‡URL
                    const imageUrl = canvas.toDataURL('image/jpeg')
                    
                    // æ’­æ”¾æ‹ç…§æ•ˆæœ
                    playCaptureEffect()
                    
                    // ç›´æ¥ç¡®è®¤å›¾ç‰‡ï¼Œæ— éœ€æ˜¾ç¤ºé¢„è§ˆ
                    emit('image-confirmed', imageUrl)
                    
                    return imageUrl
                }
                return null
            } catch (error) {
                console.error('æ•è·å›¾åƒå¤±è´¥:', error)
                return null
            }
        }

        const stopCamera = () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop())
                mediaStream = null
            }
        }

        onMounted(() => {
            initializeCamera()
        })

        onUnmounted(() => {
            stopCamera()
        })

        return {
            videoEl,
            captureEffectActive,
            captureEffectType,
            effectBinding,
            noCamera,
            switchCamera,
            toggleFlash,
            captureImage,
            setCaptureEffectType
        }
    }
})
</script>

<style scoped>
.camera-screen {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background-color: #000;
    z-index: 1;
    transition: all 0.3s ease;
}

/* 1. åŸºç¡€ç¼©æ”¾æ•ˆæœ */
.capture-effect {
    transform: scale(0.95);
    opacity: 0.9;
}

/* 2. é—ªå…‰ç¯æ•ˆæœ */
.flash-effect {
    position: relative;
}

.flash-effect::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(255, 255, 255, 0.8);
    animation: flash 0.2s ease-out;
    pointer-events: none;
    z-index: 3;
}

@keyframes flash {
    from { opacity: 1; }
    to { opacity: 0; }
}

/* 3. å¿«é—¨æ•ˆæœ */
.shutter-effect {
    animation: shutter 0.4s cubic-bezier(0.25, 0.1, 0.25, 1);
}

@keyframes shutter {
    0% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(1);
    }
    15% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(0.97);
    }
    30% { 
        clip-path: inset(50% 0% 50% 0%);
        transform: scale(0.9);
    }
    50% { 
        clip-path: inset(50% 50% 50% 50%);
        transform: scale(0.9);
    }
    80% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(0.95);
    }
    100% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(1);
    }
}

/* 4. æ‰«æçº¿æ•ˆæœ */
.scan-effect {
    position: relative;
}

.scan-effect::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 2px;
    background-color: rgba(0, 255, 255, 0.8);
    box-shadow: 0 0 10px #00ffff, 0 0 20px #00ffff;
    z-index: 5;
    animation: scanLine 0.6s linear;
    pointer-events: none;
}

@keyframes scanLine {
    from { top: 0; }
    to { top: 100%; }
}

/* 5. è„‰å†²è¾¹æ¡†æ•ˆæœ */
.pulse-effect {
    position: relative;
    transform: scale(0.98);
    transition: transform 0.2s;
}

.pulse-effect::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    border: 3px solid #fe2c55;
    z-index: 5;
    animation: pulseBorder 0.8s ease-out;
    pointer-events: none;
}

@keyframes pulseBorder {
    0% { 
        opacity: 1;
        transform: scale(0.95);
    }
    50% { 
        opacity: 0.5;
        transform: scale(1.02);
    }
    100% { 
        opacity: 0;
        transform: scale(1.05);
    }
}

.video {
    width: 100%;
    height: 100%;
    object-fit: cover;
}

.no-camera-message {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #fff;
    text-align: center;
}

.message-content {
    padding: 20px;
    border-radius: 10px;
    background-color: rgba(0, 0, 0, 0.5);
}

.message-icon {
    font-size: 48px;
    margin-bottom: 10px;
}

.message-text {
    font-size: 18px;
    font-weight: bold;
    margin-bottom: 8px;
}

.message-subtext {
    font-size: 14px;
    opacity: 0.8;
}
</style> 