<template>
    <div 
        class="camera-screen" 
        :class="effectBinding"
    >
        <video ref="videoEl" class="video" autoplay playsinline v-if="!noCamera"></video>
        <canvas ref="filterCanvasEl" class="canvas filter-canvas" v-if="!noCamera"></canvas>
        <canvas ref="decorationCanvasEl" class="canvas decoration-canvas" v-if="!noCamera"></canvas>
        <div v-if="noCamera" class="no-camera-message">
            <div class="message-content">
                <div class="message-icon">ğŸ“·</div>
                <div class="message-text">æœªæ£€æµ‹åˆ°æ‘„åƒå¤´</div>
                <div class="message-subtext">è¯·ä½¿ç”¨å…¶ä»–æ–¹å¼ä¸Šä¼ ç…§ç‰‡</div>
            </div>
        </div>
    </div>
</template>

<script lang="ts">
import { defineComponent, ref, onMounted, onUnmounted, computed } from 'vue'
import { CameraDirection } from '@/utils/web-capacitor-adapter'
import { 
    CaptureEffectType, 
    createEffectClassBinding,
    getEffectDuration
} from './captureEffects'
import { faceEffectService } from '@/services/faceEffectService'
import { decorationEffectService } from '@/services/decorationEffectService'

export default defineComponent({
    name: 'CameraScreen',
    setup() {
        const videoEl = ref<HTMLVideoElement | null>(null)
        const filterCanvasEl = ref<HTMLCanvasElement | null>(null)
        const decorationCanvasEl = ref<HTMLCanvasElement | null>(null)
        let mediaStream: MediaStream | null = null
        const captureEffectActive = ref<boolean>(false)
        const noCamera = ref<boolean>(false)
        let animationFrameId: number | null = null
        let lastFrameTime = 0
        let frameCount = 0
        
        // å½“å‰ä½¿ç”¨çš„æ‹ç…§æ•ˆæœç±»å‹
        const captureEffectType = ref<CaptureEffectType>('pulse')

        // è®¡ç®—å½“å‰æ•ˆæœçš„ç±»ç»‘å®š
        const effectBinding = computed(() => 
            createEffectClassBinding(captureEffectType.value, captureEffectActive.value)
        )

        // æ€§èƒ½ç›‘æ§ - ç®€åŒ–ç‰ˆ
        const measurePerformance = (timestamp: number) => {
            if (!lastFrameTime) {
                lastFrameTime = timestamp
                frameCount = 0
            }

            frameCount++
            const elapsed = timestamp - lastFrameTime

            if (elapsed >= 1000) {
                frameCount = 0
                lastFrameTime = timestamp
            }

            animationFrameId = requestAnimationFrame(measurePerformance)
        }

        const initializeCamera = async (direction: string = CameraDirection.Rear) => {
            try {
                // æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦æ”¯æŒgetUserMedia
                if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                    console.error('æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ‘„åƒå¤´åŠŸèƒ½')
                    noCamera.value = true
                    return
                }

                // åœæ­¢ä¹‹å‰çš„æµ
                if (mediaStream) {
                    mediaStream.getTracks().forEach(track => track.stop())
                }

                // è¯·æ±‚æ‘„åƒå¤´æƒé™
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: direction === CameraDirection.Front ? 'user' : 'environment',
                        width: { ideal: 1920 },
                        height: { ideal: 1080 }
                    }
                })

                // è®¾ç½®è§†é¢‘æº
                if (videoEl.value) {
                    videoEl.value.srcObject = mediaStream
                    
                    // ç­‰å¾…è§†é¢‘å…ƒæ•°æ®åŠ è½½å®Œæˆ
                    await new Promise((resolve) => {
                        videoEl.value!.onloadedmetadata = () => {
                            resolve(true)
                        }
                    })

                    // è®¾ç½®Canvaså°ºå¯¸
                    if (filterCanvasEl.value && decorationCanvasEl.value) {
                        const container = filterCanvasEl.value.parentElement
                        if (container) {
                            const rect = container.getBoundingClientRect()
                            const videoRatio = videoEl.value.videoWidth / videoEl.value.videoHeight

                            // è®¡ç®—Canvaså°ºå¯¸ - ç¡®ä¿é«˜åº¦é€‚åº”å®¹å™¨ï¼Œå®½åº¦è‡ªé€‚åº”ä¸”å±…ä¸­
                            let canvasWidth, canvasHeight
                            
                            // å§‹ç»ˆè®©é«˜åº¦é€‚åº”å®¹å™¨
                            canvasHeight = rect.height 
                            // å®½åº¦æ ¹æ®è§†é¢‘æ¯”ä¾‹è‡ªé€‚åº”
                            canvasWidth = canvasHeight * videoRatio
                            
                            // è®¾ç½®Canvaså°ºå¯¸
                            filterCanvasEl.value.width = canvasWidth
                            filterCanvasEl.value.height = canvasHeight
                            if (decorationCanvasEl.value) {
                                decorationCanvasEl.value.width = canvasWidth
                                decorationCanvasEl.value.height = canvasHeight
                            }
                        }
                    }
                }

                // å¼€å§‹æ€§èƒ½ç›‘æ§
                animationFrameId = requestAnimationFrame(measurePerformance)

                // åˆå§‹åŒ–ç¾é¢œæœåŠ¡ï¼Œä¼ é€’ä¸¤ä¸ªcanvas
                if (videoEl.value && filterCanvasEl.value && decorationCanvasEl.value) {
                    await faceEffectService.initialize(videoEl.value, filterCanvasEl.value)
                    await decorationEffectService.initialize(decorationCanvasEl.value)
                }

                // é‡ç½®æ•è·çŠ¶æ€
                noCamera.value = false
            } catch (error) {
                console.error('æ— æ³•è®¿é—®æ‘„åƒå¤´:', error)
                noCamera.value = true
            }
        }

        const switchCamera = (direction: string) => {
            initializeCamera(direction)
        }

        const toggleFlash = async (enabled: boolean) => {
            if (!mediaStream || noCamera.value) return

            try {
                const track = mediaStream.getVideoTracks()[0]
                if (track) {
                    const capabilities = track.getCapabilities()
                    // æ£€æŸ¥æ˜¯å¦æ”¯æŒé—ªå…‰ç¯
                    if ('torch' in capabilities) {
                        await track.applyConstraints({
                            advanced: [{ torch: enabled } as any]
                        })
                    } else {
                        console.warn('å½“å‰è®¾å¤‡ä¸æ”¯æŒé—ªå…‰ç¯æ§åˆ¶')
                    }
                }
            } catch (error) {
                console.error('æ§åˆ¶é—ªå…‰ç¯å¤±è´¥:', error)
            }
        }
        
        // è®¾ç½®æ‹ç…§æ•ˆæœç±»å‹
        const setCaptureEffectType = (type: CaptureEffectType) => {
            captureEffectType.value = type
            // console.log(`å·²åˆ‡æ¢åˆ°${type}æ‹ç…§æ•ˆæœ`)
        }

        // æ’­æ”¾æ‹ç…§æ•ˆæœ
        const playCaptureEffect = () => {
            captureEffectActive.value = true
            
            // è·å–å½“å‰æ•ˆæœçš„æŒç»­æ—¶é—´
            const duration = getEffectDuration(captureEffectType.value)
            
            setTimeout(() => {
                captureEffectActive.value = false
            }, duration)
        }

        const captureImage = async (): Promise<string | null> => {
            if (noCamera.value) {
                // æ²¡æœ‰æ‘„åƒå¤´æ—¶ï¼Œæ‰“å¼€æ–‡ä»¶é€‰æ‹©å™¨
                return new Promise((resolve, reject) => {
                    const input = document.createElement('input')
                    input.type = 'file'
                    input.accept = 'image/*'
                    
                    input.onchange = (e: Event) => {
                        const target = e.target as HTMLInputElement
                        if (target.files && target.files[0]) {
                            const file = target.files[0]
                            const reader = new FileReader()
                            reader.onload = () => {
                                const imageUrl = reader.result as string
                                // æ’­æ”¾æ‹ç…§æ•ˆæœ
                                playCaptureEffect()
                                resolve(imageUrl)
                            }
                            reader.onerror = reject
                            reader.readAsDataURL(file)
                        } else {
                            reject(new Error('æœªé€‰æ‹©å›¾ç‰‡'))
                        }
                    }
                    
                    input.click()
                })
            }
            
            if (!filterCanvasEl.value) return null

            try {
                const width = filterCanvasEl.value.width;
                const height = filterCanvasEl.value.height;
                const tempCanvas = document.createElement('canvas');
                tempCanvas.width = width;
                tempCanvas.height = height;
                const ctx = tempCanvas.getContext('2d');

                // å¼ºåˆ¶ WebGL flushï¼Œç¡®ä¿å†…å®¹å¯è¯»
                const gl = filterCanvasEl.value.getContext('webgl');
                if (gl && gl.flush) gl.flush();

                // å…ˆç»˜åˆ¶æ»¤é•œå±‚
                ctx?.drawImage(filterCanvasEl.value, 0, 0, width, height);

                // å†å åŠ è£…é¥°å±‚
                if (decorationCanvasEl.value) {
                    ctx?.drawImage(decorationCanvasEl.value, 0, 0, width, height);
                }

                // å¯¼å‡ºåˆæˆåçš„å›¾ç‰‡
                const imageUrl = tempCanvas.toDataURL('image/jpeg');
                playCaptureEffect();
                return imageUrl;
            } catch (error) {
                console.error('æ•è·å›¾åƒå¤±è´¥:', error);
                return null;
            }
        }

        const stopCamera = () => {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop())
                mediaStream = null
            }
            faceEffectService.stop()
            decorationEffectService.stop()
        }

        // æ·»åŠ çª—å£å¤§å°å˜åŒ–ç›‘å¬
        const handleResize = () => {
            if (filterCanvasEl.value && videoEl.value) {
                const container = filterCanvasEl.value.parentElement
                if (container) {
                    const rect = container.getBoundingClientRect()
                    const videoRatio = videoEl.value.videoWidth / videoEl.value.videoHeight
                    
                    // è®¡ç®—Canvaså°ºå¯¸ - ç¡®ä¿é«˜åº¦é€‚åº”å®¹å™¨ï¼Œå®½åº¦è‡ªé€‚åº”ä¸”å±…ä¸­
                    let canvasWidth, canvasHeight
                    
                    // å§‹ç»ˆè®©é«˜åº¦é€‚åº”å®¹å™¨
                    canvasHeight = rect.height 
                    // å®½åº¦æ ¹æ®è§†é¢‘æ¯”ä¾‹è‡ªé€‚åº”
                    canvasWidth = canvasHeight * videoRatio
                    
                    // è®¾ç½®Canvaså°ºå¯¸
                    filterCanvasEl.value.width = canvasWidth
                    filterCanvasEl.value.height = canvasHeight
                    if (decorationCanvasEl.value) {
                        decorationCanvasEl.value.width = canvasWidth
                        decorationCanvasEl.value.height = canvasHeight
                    }
                }
            }
        }

        onMounted(() => {
            initializeCamera()
            window.addEventListener('resize', handleResize)
        })

        onUnmounted(() => {
            stopCamera()
            window.removeEventListener('resize', handleResize)
            if (animationFrameId) {
                cancelAnimationFrame(animationFrameId)
            }
        })

        return {
            videoEl,
            filterCanvasEl,
            decorationCanvasEl,
            captureEffectActive,
            captureEffectType,
            effectBinding,
            noCamera,
            switchCamera,
            toggleFlash,
            captureImage,
            setCaptureEffectType
        }
    }
})
</script>

<style scoped>
.camera-screen {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background-color: #000;
    z-index: 1;
    transition: all 0.3s ease;
}

/* 1. åŸºç¡€ç¼©æ”¾æ•ˆæœ */
.capture-effect {
    transform: scale(0.95);
    opacity: 0.9;
}

/* 2. é—ªå…‰ç¯æ•ˆæœ */
.flash-effect {
    position: relative;
}

.flash-effect::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    background-color: rgba(255, 255, 255, 0.8);
    animation: flash 0.2s ease-out;
    pointer-events: none;
    z-index: 3;
}

@keyframes flash {
    from { opacity: 1; }
    to { opacity: 0; }
}

/* 3. å¿«é—¨æ•ˆæœ */
.shutter-effect {
    animation: shutter 0.4s cubic-bezier(0.25, 0.1, 0.25, 1);
}

@keyframes shutter {
    0% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(1);
    }
    15% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(0.97);
    }
    30% { 
        clip-path: inset(50% 0% 50% 0%);
        transform: scale(0.9);
    }
    50% { 
        clip-path: inset(50% 50% 50% 50%);
        transform: scale(0.9);
    }
    80% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(0.95);
    }
    100% { 
        clip-path: inset(0% 0% 0% 0%);
        transform: scale(1);
    }
}

/* 4. æ‰«æçº¿æ•ˆæœ */
.scan-effect {
    position: relative;
}

.scan-effect::after {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 2px;
    background-color: rgba(0, 255, 255, 0.8);
    box-shadow: 0 0 10px #00ffff, 0 0 20px #00ffff;
    z-index: 5;
    animation: scanLine 0.6s linear;
    pointer-events: none;
}

@keyframes scanLine {
    from { top: 0; }
    to { top: 100%; }
}

/* 5. è„‰å†²è¾¹æ¡†æ•ˆæœ */
.pulse-effect {
    position: relative;
    transform: scale(0.98);
    transition: transform 0.2s;
}

.pulse-effect::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    bottom: 0;
    border: 3px solid #fe2c55;
    z-index: 5;
    animation: pulseBorder 0.8s ease-out;
    pointer-events: none;
}

@keyframes pulseBorder {
    0% { 
        opacity: 1;
        transform: scale(0.95);
    }
    50% { 
        opacity: 0.5;
        transform: scale(1.02);
    }
    100% { 
        opacity: 0;
        transform: scale(1.05);
    }
}

.video {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
}

.canvas {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    pointer-events: none;
}

.filter-canvas { 
    z-index: 1; 
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    max-width: none;
    max-height: 100%;
    width: auto;
    height: auto;
}
.decoration-canvas { 
    z-index: 2;
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    max-width: none;
    max-height: 100%;
    width: auto;
    height: auto;
}

.no-camera-message {
    width: 100%;
    height: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
    color: #fff;
    text-align: center;
}

.message-content {
    padding: 20px;
    border-radius: 10px;
    background-color: rgba(0, 0, 0, 0.5);
}

.message-icon {
    font-size: 48px;
    margin-bottom: 10px;
}

.message-text {
    font-size: 18px;
    font-weight: bold;
    margin-bottom: 8px;
}

.message-subtext {
    font-size: 14px;
    opacity: 0.8;
}
</style> 